<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>AI | Robert | 程序员 · 生活家</title>
<meta name=keywords content><meta name=description content="80后程序员，北邮本硕，信息与计算机专业。在代码与诗意之间寻找平衡。"><meta name=author content="Robert"><link rel=canonical href=/tags/ai/><link crossorigin=anonymous href=/assets/css/stylesheet.6a98292fb8fa8cf0f3ba4042d4b75515c04267550f3ad49ff6271b5af9562443.css integrity="sha256-apgpL7j6jPDzukBC1LdVFcBCZ1UPOtSf9icbWvlWJEM=" rel="preload stylesheet" as=style><link rel=icon href=/favicon.ico><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=apple-touch-icon href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=/tags/ai/index.xml><link rel=alternate hreflang=en href=/tags/ai/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><meta property="og:title" content="AI"><meta property="og:description" content="80后程序员，北邮本硕，信息与计算机专业。在代码与诗意之间寻找平衡。"><meta property="og:type" content="website"><meta property="og:url" content="/tags/ai/"><meta name=twitter:card content="summary"><meta name=twitter:title content="AI"><meta name=twitter:description content="80后程序员，北邮本硕，信息与计算机专业。在代码与诗意之间寻找平衡。"></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=/ accesskey=h title="Robert | 程序员 · 生活家 (Alt + H)">Robert | 程序员 · 生活家</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=/tech/ title="💻 专业"><span>💻 专业</span></a></li><li><a href=/life/ title="🍃 人生"><span>🍃 人生</span></a></li><li><a href=/music/ title="🎵 兴趣"><span>🎵 兴趣</span></a></li><li><a href=/literature/ title="📜 文学"><span>📜 文学</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=/>Home</a>&nbsp;»&nbsp;<a href=/tags/>Tags</a></div><h1>AI
<a href=index.xml title=RSS aria-label=RSS><svg viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" height="23"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></h1></header><article class="post-entry tag-entry"><header class=entry-header><h2>MemGPT/Letta 记忆与上下文管理深度解析</h2></header><div class=entry-content><p>本文档整理自 Letta 官方文档、研究论文及 GitHub 仓库
原项目：MemGPT → 现名 Letta
论文：arXiv:2310.08560
📌 项目概览 什么是 MemGPT/Letta？ MemGPT（Memory-GPT）是一个创新的 LLM 记忆管理系统，现更名为 Letta。它由 UC Berkeley 的研究团队开发，旨在解决大语言模型的上下文窗口限制问题。
核心理念：
“Teaching LLMs to manage their own memory for unbounded context”
让 LLM 学会管理自己的记忆，实现无限上下文
GitHub 数据：
⭐ 21.2k stars 🍴 2.2k forks 👥 158 位贡献者 🧠 核心问题：上下文窗口限制 现有 LLM 的痛点 有限上下文窗口
GPT-4: 128K tokens Claude: 200K tokens 长文档、多轮对话容易溢出 无法持久化记忆
每次对话都是"从头开始" 无法记住用户偏好、历史交互 无法进行长期学习
不能从交互中积累知识 无法自我改进 🎯 解决方案：虚拟上下文管理 核心创新：操作系统启发 MemGPT 借鉴了传统操作系统的虚拟内存机制：
...</p></div><footer class=entry-footer>&lt;span title='2026-02-22 20:50:00 +0800 CST'>February 22, 2026&lt;/span>&amp;nbsp;·&amp;nbsp;3 min&amp;nbsp;·&amp;nbsp;599 words&amp;nbsp;·&amp;nbsp;Robert</footer><a class=entry-link aria-label="post link to MemGPT/Letta 记忆与上下文管理深度解析" href=/tech/memgpt-letta-guide/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>Agent Infra 深度调研：Memory管理层次与架构设计</h2></header><div class=entry-content><p>执行摘要 本报告对Agent Infrastructure（Agent基础设施）领域进行了系统性深度调研，重点关注Memory管理层次模型。通过对LangChain、LangGraph、LangSmith、Zep、MemGPT等主流技术的分析，揭示了Agent Memory从简单会话存储到复杂知识图谱演进的技术脉络。
1. Agent Infra 分层架构 1.1 Agent执行动态追踪（Trace）层 LangSmith 是LangChain团队推出的LLM应用可观测性平台，截至2025年已处理超过10亿条Trace。
核心架构：
Frontend (UI) + Backend API + SDK (Python/TypeScript) ↓ ClickHouse (Trace存储) + PostgreSQL (元数据) + Redis (缓存) 定价模式：
Developer计划：免费，5,000 traces/月 Plus计划：$39/月/席位 Enterprise计划：支持私有化部署 1.2 Agent Context管理层 Context生命周期：
创建(Creation) → 传递(Transfer) → 更新(Update) → 销毁(Dispose) │ │ │ │ 初始化状态 节点间流转 Reducer合并 会话结束 LangGraph中的Context管理：
class AgentState(TypedDict): messages: Annotated[list, add_messages] documents: list[str] counter: Annotated[int, add] 2. Memory管理深度分析（重点） 2.1 Memory层次模型 基于认知科学和计算机体系结构的启发，Agent Memory采用分层架构：
┌─────────────────────────────────────────────────────────┐ │ Working Memory (工作记忆) │ │ Context Window / Active Reasoning │ │ ~4K-128K tokens │ │ ▲ │ │ │ 实时访问 │ ├───────────────────┼─────────────────────────────────────┤ │ ▼ │ │ Short-term Memory (短期记忆) │ │ Session History / Conversation Buffer │ │ ~10-100 messages │ │ ▲ │ │ │ 快速检索 │ ├───────────────────┼─────────────────────────────────────┤ │ ▼ │ │ Long-term Memory (长期记忆) │ │ ┌───────────────┬───────────────┐ │ │ │ Fixed Attr │ Fuzzy Vector │ │ │ │ Memory │ Memory │ │ │ │ (用户画像) │ (Embedding) │ │ │ └───────────────┴───────────────┘ │ └─────────────────────────────────────────────────────────┘ 2.2 短期记忆（Short-term Memory） 工作记忆（Working Memory）：
...</p></div><footer class=entry-footer>&lt;span title='2026-02-22 20:40:00 +0800 CST'>February 22, 2026&lt;/span>&amp;nbsp;·&amp;nbsp;3 min&amp;nbsp;·&amp;nbsp;586 words&amp;nbsp;·&amp;nbsp;Robert</footer><a class=entry-link aria-label="post link to Agent Infra 深度调研：Memory管理层次与架构设计" href=/tech/agent-infra-memory/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>多模态数据湖深度调研报告</h2></header><div class=entry-content><p>执行摘要 本报告对多模态数据湖领域进行系统性深度调研，涵盖架构设计、存储格式、查询优化、数据治理及业界实践等核心维度。随着AI原生时代的到来，数据湖正经历从结构化分析向多模态AI就绪架构的根本性演进。
一、多模态数据湖架构 1.1 现代多模态数据湖核心架构组件 现代多模态数据湖采用分层解耦架构，各层职责明确：
访问层 (Jupyter/BI工具/ML框架/Agent接口) ↓ 计算层 (Spark/Flink/Trino/DuckDB/PyTorch/Ray) ↓ 表格式层 (Delta Lake/Iceberg/Hudi/Paimon) ↓ 存储格式层 (Parquet/Lance/ORC/Arrow) ↓ 对象存储层 (S3/GCS/Azure Blob/OSS) 核心组件解析：
组件层级 核心功能 代表技术 对象存储层 海量数据持久化、高可用、低成本 Amazon S3, 阿里云OSS 存储格式层 数据序列化、压缩、列式/行式布局 Parquet, Lance, Arrow 表格式层 ACID事务、Schema演进、版本控制 Iceberg, Delta Lake, Hudi 计算层 查询处理、ETL、ML训练 Spark, Flink, DuckDB 访问层 数据消费、可视化、应用集成 Tableau, Jupyter, LangChain 1.2 Data Lakehouse架构特点与优势 Lakehouse核心特征：
开放格式存储：基于Parquet/ORC等开放列式格式，避免厂商锁定 ACID事务支持：通过表格式层实现事务一致性 Schema演进：支持字段增删改，无需重写数据 时间旅行：数据版本回溯，支持可重现分析 统一批流：同一份数据支持批处理和流处理 Lakehouse vs 传统架构对比：
维度 传统数据仓库 数据湖 Lakehouse 数据类型 结构化为主 全类型 全类型 ACID支持 强 无 强 Schema管理 严格 灵活 灵活+演进 性能 高 低 高 成本 高 低 低 AI/ML支持 弱 中等 强 二、存储格式深度分析 2.1 Parquet格式 核心优势：
...</p></div><footer class=entry-footer>&lt;span title='2026-02-22 20:35:00 +0800 CST'>February 22, 2026&lt;/span>&amp;nbsp;·&amp;nbsp;3 min&amp;nbsp;·&amp;nbsp;434 words&amp;nbsp;·&amp;nbsp;Robert</footer><a class=entry-link aria-label="post link to 多模态数据湖深度调研报告" href=/tech/multimodal-data-lake/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>自动驾驶大数据领域深度调研报告</h2></header><div class=entry-content><p>摘要 自动驾驶大数据是驱动智能驾驶技术演进的核心燃料。本报告从数据类型与特征、数据处理流程、技术挑战、主流解决方案和未来趋势五个维度，对自动驾驶大数据领域进行系统性调研，提炼核心洞察，为技术决策提供参考。
一、数据类型与特征 1.1 多模态数据类型全景 自动驾驶系统依赖多源异构传感器数据实现环境感知和决策控制，主要数据类型包括：
数据类型 传感器来源 数据特征 产生频率/规模 图像/视频数据 摄像头（8-12个） 2D视觉信息，含颜色、纹理、语义 30-60fps，每小时72-144GB 点云数据 激光雷达（LiDAR） 3D空间坐标、反射强度 10-20Hz，每小时36-252GB 毫米波雷达数据 Radar（3-5个） 距离、速度、方位角（4D成像） 10-50Hz，数据量相对较小 CAN总线数据 车辆总线系统 车速、转向角、油门/刹车踏板位置 100-1000Hz，结构化数据 DDS Topic数据 ROS2/中间件 传感器融合、决策指令、状态信息 实时流式数据 超声波数据 超声波雷达 近距离障碍物检测 低速场景辅助 GNSS/IMU数据 GPS+惯性测量单元 位置、姿态、加速度 1-100Hz 高精地图数据 预采集/实时构建 车道线、交通标志、拓扑关系 静态+动态更新 1.2 数据规模与产生速率 根据行业研究数据：
单车数据产生量：
L2级别：每小时约2TB L4-L5级别：每小时16-20TB 研发阶段单车每日：近10TB 商用阶段单车每日：约2TB fleet级数据规模：
特斯拉：全球近200万辆车，每天提供约1600亿帧视频用于训练 累计数据量：特斯拉已收集超过30PB视频数据（2022年） 训练数据：1000万个精选人类驾驶视频（2023年初） 1.3 数据结构化程度分布 数据类型 格式示例 占比估算 特点 非结构化数据 原始视频、点云、图像 ~70-80% 体量大、处理复杂、价值密度低 半结构化数据 ROS bag、JSON、Protobuf ~15-20% 包含元数据和原始数据的混合 结构化数据 Parquet、CSV、CAN信号 ~5-10% 易于查询分析、价值密度高 关键洞察：自动驾驶数据的"冰山模型"——可见的标注数据和结构化数据仅占小部分，海量的原始非结构化数据才是训练端到端模型的关键。
...</p></div><footer class=entry-footer>&lt;span title='2026-02-22 20:30:00 +0800 CST'>February 22, 2026&lt;/span>&amp;nbsp;·&amp;nbsp;2 min&amp;nbsp;·&amp;nbsp;246 words&amp;nbsp;·&amp;nbsp;Robert</footer><a class=entry-link aria-label="post link to 自动驾驶大数据领域深度调研报告" href=/tech/autonomous-driving-big-data/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>智能体设计模式资料汇总</h2></header><div class=entry-content><p>这是 Google 及相关高质量智能体设计模式的资料整理，涵盖从理论基础到实践应用的完整内容。
📚 中文资料 1. Prompt Engineering Guide - 大语言模型智能体简介 ⭐推荐 网址: https://www.promptingguide.ai/zh/research/llm-agents 语言: 中文 内容: 系统性介绍 LLM Agent 的核心组件 智能体（Agent）角色与设计 规划模块（Planning）：无反馈规划 vs 有反馈规划 记忆模块（Memory）：短期记忆与长期记忆 工具使用（Tools）：API、代码解释器等 ReAct、Reflexion 等设计模式 📚 英文资料（高质量参考） 2. A Survey on LLM-based Autonomous Agents ⭐经典论文 网址: https://arxiv.org/abs/2308.11432 PDF: https://arxiv.org/pdf/2308.11432 作者: 中国人民大学高瓴人工智能学院 内容: LLM Agent 的统一框架 社交科学、自然科学、工程领域的应用 评估策略与未来方向 3. DeepLearning.AI - Multi AI Agent Systems with crewAI 网址: https://www.deeplearning.ai/short-courses/multi-ai-agent-systems-with-crewai/ 时长: 2小时41分钟，18个视频课程 内容: 角色扮演（Role-playing） 记忆系统（短期/长期/共享记忆） 工具分配（Tools） 任务协作（串行、并行、层级） Guardrails 错误处理 4. LangChain 官方文档 - Agentic Concepts 网址: https://js.langchain.com/docs/concepts/agentic/ 内容: LangChain 的 Agent 架构 LangGraph 编排框架 Deep Agents 现代功能（自动压缩、虚拟文件系统、子代理） 🔗 Google 官方资源 资源 链接 Vertex AI Agent Builder https://cloud.google.com/generative-ai-app-builder/docs/agent-intro Gemini API Agents 文档 https://ai.google.dev/gemini-api/docs/agents Google Research https://research.google/pubs/ Kaggle Agents 白皮书 https://www.kaggle.com/whitepaper-agents 📋 核心设计模式总结 模式 说明 ReAct 推理+行动交替进行（Thought → Action → Observation） Chain-of-Thought 思维链，逐步推理 Tree of Thoughts 多路径思维树 Reflexion 自我反思与改进 Multi-Agent 多智能体协作（角色分工） RAG 检索增强生成 Tool Use 工具调用（搜索、代码解释器等） 📝 延伸阅读 MRKL: 结合 LLM 和专家模块 https://arxiv.org/abs/2205.00445 Toolformer: 微调 LLM 使用外部工具 API https://arxiv.org/abs/2302.04761 HuggingGPT: 利用 LLM 作为任务规划器 https://arxiv.org/abs/2303.17580 ChemCrow: 化学领域专用 Agent https://arxiv.org/abs/2304.05376 持续学习中，欢迎交流讨论。
...</p></div><footer class=entry-footer>&lt;span title='2026-02-22 15:00:00 +0800 CST'>February 22, 2026&lt;/span>&amp;nbsp;·&amp;nbsp;1 min&amp;nbsp;·&amp;nbsp;159 words&amp;nbsp;·&amp;nbsp;Robert</footer><a class=entry-link aria-label="post link to 智能体设计模式资料汇总" href=/tech/agent-design-patterns/></a></article></main><footer class=footer><span>&copy; 2026 <a href=/>Robert | 程序员 · 生活家</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>