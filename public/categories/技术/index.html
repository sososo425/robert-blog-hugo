<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>技术 | Robert | 程序员 · 生活家</title>
<meta name=keywords content><meta name=description content="80后程序员，北邮本硕，信息与计算机专业。在代码与诗意之间寻找平衡。"><meta name=author content="Robert"><link rel=canonical href=https://robert-xblog.vercel.app/categories/%E6%8A%80%E6%9C%AF/><link crossorigin=anonymous href=/assets/css/stylesheet.6a98292fb8fa8cf0f3ba4042d4b75515c04267550f3ad49ff6271b5af9562443.css integrity="sha256-apgpL7j6jPDzukBC1LdVFcBCZ1UPOtSf9icbWvlWJEM=" rel="preload stylesheet" as=style><link rel=icon href=https://robert-xblog.vercel.app/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://robert-xblog.vercel.app/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://robert-xblog.vercel.app/favicon-32x32.png><link rel=apple-touch-icon href=https://robert-xblog.vercel.app/apple-touch-icon.png><link rel=mask-icon href=https://robert-xblog.vercel.app/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://robert-xblog.vercel.app/categories/%E6%8A%80%E6%9C%AF/index.xml><link rel=alternate hreflang=en href=https://robert-xblog.vercel.app/categories/%E6%8A%80%E6%9C%AF/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><meta property="og:title" content="技术"><meta property="og:description" content="80后程序员，北邮本硕，信息与计算机专业。在代码与诗意之间寻找平衡。"><meta property="og:type" content="website"><meta property="og:url" content="https://robert-xblog.vercel.app/categories/%E6%8A%80%E6%9C%AF/"><meta name=twitter:card content="summary"><meta name=twitter:title content="技术"><meta name=twitter:description content="80后程序员，北邮本硕，信息与计算机专业。在代码与诗意之间寻找平衡。"></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://robert-xblog.vercel.app/ accesskey=h title="Robert | 程序员 · 生活家 (Alt + H)">Robert | 程序员 · 生活家</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=https://robert-xblog.vercel.app/tech/ title="💻 专业"><span>💻 专业</span></a></li><li><a href=https://robert-xblog.vercel.app/life/ title="🍃 人生"><span>🍃 人生</span></a></li><li><a href=https://robert-xblog.vercel.app/music/ title="🎵 兴趣"><span>🎵 兴趣</span></a></li><li><a href=https://robert-xblog.vercel.app/literature/ title="📜 文学"><span>📜 文学</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://robert-xblog.vercel.app/>Home</a>&nbsp;»&nbsp;<a href=https://robert-xblog.vercel.app/categories/>Categories</a></div><h1>技术
<a href=index.xml title=RSS aria-label=RSS><svg viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" height="23"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></h1></header><article class="post-entry tag-entry"><header class=entry-header><h2>MemGPT 论文中文翻译：将 LLM 作为操作系统</h2></header><div class=entry-content><p>原文标题: MemGPT: Towards LLMs as Operating Systems 作者: Charles Packer, Sarah Wooders, Kevin Lin, Vivian Fang, Shishir G. Patil, Ion Stoica, Joseph E. Gonzalez 机构: 加州大学伯克利分校 arXiv: 2310.08560v2 [cs.AI] 2024年2月12日 翻译整理: 2025年2月
摘要 大语言模型（LLM）已经彻底改变了人工智能领域，但受到有限的上下文窗口限制，这阻碍了它们在扩展对话和文档分析等任务中的实用性。为了能够在有限的上下文窗口之外使用上下文，我们提出了虚拟上下文管理技术，这一技术借鉴了传统操作系统中的分层内存系统，通过物理内存和磁盘之间的分页来提供扩展虚拟内存的幻觉。
利用这一技术，我们引入了 MemGPT（MemoryGPT），这是一个能够智能管理不同存储层级的系统，以在 LLM 有限的上下文窗口内有效提供扩展上下文。我们在两个领域评估了受操作系统启发的设计，在这些领域中，现代 LLM 的有限上下文窗口严重限制了它们的性能：
文档分析：MemGPT 能够分析远超底层 LLM 上下文窗口的大型文档 多会话聊天：MemGPT 可以创建能够记住、反思并通过与用户的长期互动动态进化的对话智能体 我们在 https://research.memgpt.ai 发布了 MemGPT 代码和实验数据。
图 1. MemGPT（左）在收到关于有限上下文空间的系统警报后将数据写入持久内存。
图 2. MemGPT（左）可以搜索上下文外数据，将相关信息带入当前上下文窗口。
1. 引言 近年来，大语言模型（LLM）及其底层的 Transformer 架构（Vaswani et al., 2017; Devlin et al., 2018; Brown et al., 2020; Ouyang et al., 2022）已成为对话式人工智能的基石，并催生了广泛的消费者和企业应用。尽管取得了这些进展，LLM 使用的有限固定长度上下文窗口显著阻碍了它们对长对话或长文档推理的适用性。例如，最广泛使用的开源 LLM 只能支持几十轮来回消息或推理短文档，然后就会超过其最大输入长度（Touvron et al., 2023）。
...</p></div><footer class=entry-footer><span title='2026-02-22 21:30:00 +0800 CST'>February 22, 2026</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;583 words&nbsp;·&nbsp;Robert</footer><a class=entry-link aria-label="post link to MemGPT 论文中文翻译：将 LLM 作为操作系统" href=https://robert-xblog.vercel.app/tech/memgpt-paper-translation/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>MemGPT/Letta 记忆与上下文管理深度解析</h2></header><div class=entry-content><p>本文档整理自 Letta 官方文档、研究论文及 GitHub 仓库
原项目：MemGPT → 现名 Letta
论文：arXiv:2310.08560
📌 项目概览 什么是 MemGPT/Letta？ MemGPT（Memory-GPT）是一个创新的 LLM 记忆管理系统，现更名为 Letta。它由 UC Berkeley 的研究团队开发，旨在解决大语言模型的上下文窗口限制问题。
核心理念：
“Teaching LLMs to manage their own memory for unbounded context”
让 LLM 学会管理自己的记忆，实现无限上下文
GitHub 数据：
⭐ 21.2k stars 🍴 2.2k forks 👥 158 位贡献者 🧠 核心问题：上下文窗口限制 现有 LLM 的痛点 有限上下文窗口
GPT-4: 128K tokens Claude: 200K tokens 长文档、多轮对话容易溢出 无法持久化记忆
每次对话都是"从头开始" 无法记住用户偏好、历史交互 无法进行长期学习
不能从交互中积累知识 无法自我改进 🎯 解决方案：虚拟上下文管理 核心创新：操作系统启发 MemGPT 借鉴了传统操作系统的虚拟内存机制：
...</p></div><footer class=entry-footer><span title='2026-02-22 20:50:00 +0800 CST'>February 22, 2026</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;599 words&nbsp;·&nbsp;Robert</footer><a class=entry-link aria-label="post link to MemGPT/Letta 记忆与上下文管理深度解析" href=https://robert-xblog.vercel.app/tech/memgpt-letta-guide/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>三域融合分析：存储管理视角的统一</h2></header><div class=entry-content><p>执行摘要 本报告从存储管理视角对自动驾驶大数据、多模态数据湖、Agent Infra Memory管理三个领域进行深度融合分析。核心发现是：三个领域本质上都在解决同一类问题——如何在容量、延迟、成本之间取得平衡的分层存储管理问题。
一、存储管理视角的通用抽象 1.1 核心抽象模型：存储器山 (Memory Mountain) 三个领域都可以用经典的"存储器山"模型来统一描述：
访问延迟 ▲ │ ┌─────────┐ &lt;1ms │ │ 寄存器/ │ Context Window │ │ 工作记忆 │ (Working Memory) │ └─────────┘ 1-100ms │ ┌─────────┐ │ │ 缓存/ │ Session Buffer │ │ 短期记忆 │ (Short-term Memory) │ └─────────┘ 100ms-1s │ ┌─────────┐ │ │ 内存/ │ Vector DB + │ │ 中期记忆 │ Structured Store │ └─────────┘ 1s-10s │ ┌─────────┐ │ │ 磁盘/ │ Object Storage │ │ 长期记忆 │ (Long-term Memory) │ └─────────┘ >10s │ ┌─────────┐ │ │ 归档/ │ Cold Archive │ │ 永久存储 │ (Permanent Storage) │ └─────────┘ └──────────────────► 存储容量 1.2 数据/信息的层次化组织对比 维度 自动驾驶大数据 多模态数据湖 Agent Memory管理 L0: 实时流 CAN/DDS Topic流 实时摄入流 Context Window (4K-128K tokens) L1: 热数据 最近采集的ROS bag 热数据缓存 Session Buffer (10-100 messages) L2: 温数据 转换后的Parquet 温数据SSD缓存 Vector Memory + Structured Memory L3: 冷数据 OSS对象存储 对象存储(S3/OSS) 长期记忆存储 L4: 归档 冷归档存储 归档存储 永久知识库 二、分层存储模型的对比映射 2.1 “存储器山"模型的三域映射 +------------------------------------------------------------------+ | 存储器山模型 - 三域对比映射 | +--------------+------------------+------------------+---------------------------+ | 层级 | 自动驾驶大数据 | 多模态数据湖 | Agent Memory | +--------------+------------------+------------------+---------------------------+ | L0: 寄存器级 | Context Window | In-Memory Cache | Context Window (4K-128K) | | L1: 缓存级 | PolarFS Cache | L1 Memory Cache | Session Buffer | | L2: 内存级 | DataFusion | L2 SSD Cache | Vector DB + | | L3: 磁盘级 | OSS对象存储 | S3/OSS对象存储 | Long-term Memory Store | | L4: 归档级 | 冷归档存储 | Archive Storage | Permanent Knowledge Base | +--------------+------------------+------------------+---------------------------+ 2.2 层次之间的对应关系发现 关键发现：三个领域的层次结构高度同构
...</p></div><footer class=entry-footer><span title='2026-02-22 20:45:00 +0800 CST'>February 22, 2026</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;589 words&nbsp;·&nbsp;Robert</footer><a class=entry-link aria-label="post link to 三域融合分析：存储管理视角的统一" href=https://robert-xblog.vercel.app/tech/storage-fusion-analysis/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>Agent Infra 深度调研：Memory管理层次与架构设计</h2></header><div class=entry-content><p>执行摘要 本报告对Agent Infrastructure（Agent基础设施）领域进行了系统性深度调研，重点关注Memory管理层次模型。通过对LangChain、LangGraph、LangSmith、Zep、MemGPT等主流技术的分析，揭示了Agent Memory从简单会话存储到复杂知识图谱演进的技术脉络。
1. Agent Infra 分层架构 1.1 Agent执行动态追踪（Trace）层 LangSmith 是LangChain团队推出的LLM应用可观测性平台，截至2025年已处理超过10亿条Trace。
核心架构：
Frontend (UI) + Backend API + SDK (Python/TypeScript) ↓ ClickHouse (Trace存储) + PostgreSQL (元数据) + Redis (缓存) 定价模式：
Developer计划：免费，5,000 traces/月 Plus计划：$39/月/席位 Enterprise计划：支持私有化部署 1.2 Agent Context管理层 Context生命周期：
创建(Creation) → 传递(Transfer) → 更新(Update) → 销毁(Dispose) │ │ │ │ 初始化状态 节点间流转 Reducer合并 会话结束 LangGraph中的Context管理：
class AgentState(TypedDict): messages: Annotated[list, add_messages] documents: list[str] counter: Annotated[int, add] 2. Memory管理深度分析（重点） 2.1 Memory层次模型 基于认知科学和计算机体系结构的启发，Agent Memory采用分层架构：
┌─────────────────────────────────────────────────────────┐ │ Working Memory (工作记忆) │ │ Context Window / Active Reasoning │ │ ~4K-128K tokens │ │ ▲ │ │ │ 实时访问 │ ├───────────────────┼─────────────────────────────────────┤ │ ▼ │ │ Short-term Memory (短期记忆) │ │ Session History / Conversation Buffer │ │ ~10-100 messages │ │ ▲ │ │ │ 快速检索 │ ├───────────────────┼─────────────────────────────────────┤ │ ▼ │ │ Long-term Memory (长期记忆) │ │ ┌───────────────┬───────────────┐ │ │ │ Fixed Attr │ Fuzzy Vector │ │ │ │ Memory │ Memory │ │ │ │ (用户画像) │ (Embedding) │ │ │ └───────────────┴───────────────┘ │ └─────────────────────────────────────────────────────────┘ 2.2 短期记忆（Short-term Memory） 工作记忆（Working Memory）：
...</p></div><footer class=entry-footer><span title='2026-02-22 20:40:00 +0800 CST'>February 22, 2026</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;586 words&nbsp;·&nbsp;Robert</footer><a class=entry-link aria-label="post link to Agent Infra 深度调研：Memory管理层次与架构设计" href=https://robert-xblog.vercel.app/tech/agent-infra-memory/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>多模态数据湖深度调研报告</h2></header><div class=entry-content><p>执行摘要 本报告对多模态数据湖领域进行系统性深度调研，涵盖架构设计、存储格式、查询优化、数据治理及业界实践等核心维度。随着AI原生时代的到来，数据湖正经历从结构化分析向多模态AI就绪架构的根本性演进。
一、多模态数据湖架构 1.1 现代多模态数据湖核心架构组件 现代多模态数据湖采用分层解耦架构，各层职责明确：
访问层 (Jupyter/BI工具/ML框架/Agent接口) ↓ 计算层 (Spark/Flink/Trino/DuckDB/PyTorch/Ray) ↓ 表格式层 (Delta Lake/Iceberg/Hudi/Paimon) ↓ 存储格式层 (Parquet/Lance/ORC/Arrow) ↓ 对象存储层 (S3/GCS/Azure Blob/OSS) 核心组件解析：
组件层级 核心功能 代表技术 对象存储层 海量数据持久化、高可用、低成本 Amazon S3, 阿里云OSS 存储格式层 数据序列化、压缩、列式/行式布局 Parquet, Lance, Arrow 表格式层 ACID事务、Schema演进、版本控制 Iceberg, Delta Lake, Hudi 计算层 查询处理、ETL、ML训练 Spark, Flink, DuckDB 访问层 数据消费、可视化、应用集成 Tableau, Jupyter, LangChain 1.2 Data Lakehouse架构特点与优势 Lakehouse核心特征：
开放格式存储：基于Parquet/ORC等开放列式格式，避免厂商锁定 ACID事务支持：通过表格式层实现事务一致性 Schema演进：支持字段增删改，无需重写数据 时间旅行：数据版本回溯，支持可重现分析 统一批流：同一份数据支持批处理和流处理 Lakehouse vs 传统架构对比：
维度 传统数据仓库 数据湖 Lakehouse 数据类型 结构化为主 全类型 全类型 ACID支持 强 无 强 Schema管理 严格 灵活 灵活+演进 性能 高 低 高 成本 高 低 低 AI/ML支持 弱 中等 强 二、存储格式深度分析 2.1 Parquet格式 核心优势：
...</p></div><footer class=entry-footer><span title='2026-02-22 20:35:00 +0800 CST'>February 22, 2026</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;434 words&nbsp;·&nbsp;Robert</footer><a class=entry-link aria-label="post link to 多模态数据湖深度调研报告" href=https://robert-xblog.vercel.app/tech/multimodal-data-lake/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>自动驾驶大数据领域深度调研报告</h2></header><div class=entry-content><p>摘要 自动驾驶大数据是驱动智能驾驶技术演进的核心燃料。本报告从数据类型与特征、数据处理流程、技术挑战、主流解决方案和未来趋势五个维度，对自动驾驶大数据领域进行系统性调研，提炼核心洞察，为技术决策提供参考。
一、数据类型与特征 1.1 多模态数据类型全景 自动驾驶系统依赖多源异构传感器数据实现环境感知和决策控制，主要数据类型包括：
数据类型 传感器来源 数据特征 产生频率/规模 图像/视频数据 摄像头（8-12个） 2D视觉信息，含颜色、纹理、语义 30-60fps，每小时72-144GB 点云数据 激光雷达（LiDAR） 3D空间坐标、反射强度 10-20Hz，每小时36-252GB 毫米波雷达数据 Radar（3-5个） 距离、速度、方位角（4D成像） 10-50Hz，数据量相对较小 CAN总线数据 车辆总线系统 车速、转向角、油门/刹车踏板位置 100-1000Hz，结构化数据 DDS Topic数据 ROS2/中间件 传感器融合、决策指令、状态信息 实时流式数据 超声波数据 超声波雷达 近距离障碍物检测 低速场景辅助 GNSS/IMU数据 GPS+惯性测量单元 位置、姿态、加速度 1-100Hz 高精地图数据 预采集/实时构建 车道线、交通标志、拓扑关系 静态+动态更新 1.2 数据规模与产生速率 根据行业研究数据：
单车数据产生量：
L2级别：每小时约2TB L4-L5级别：每小时16-20TB 研发阶段单车每日：近10TB 商用阶段单车每日：约2TB fleet级数据规模：
特斯拉：全球近200万辆车，每天提供约1600亿帧视频用于训练 累计数据量：特斯拉已收集超过30PB视频数据（2022年） 训练数据：1000万个精选人类驾驶视频（2023年初） 1.3 数据结构化程度分布 数据类型 格式示例 占比估算 特点 非结构化数据 原始视频、点云、图像 ~70-80% 体量大、处理复杂、价值密度低 半结构化数据 ROS bag、JSON、Protobuf ~15-20% 包含元数据和原始数据的混合 结构化数据 Parquet、CSV、CAN信号 ~5-10% 易于查询分析、价值密度高 关键洞察：自动驾驶数据的"冰山模型"——可见的标注数据和结构化数据仅占小部分，海量的原始非结构化数据才是训练端到端模型的关键。
...</p></div><footer class=entry-footer><span title='2026-02-22 20:30:00 +0800 CST'>February 22, 2026</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;246 words&nbsp;·&nbsp;Robert</footer><a class=entry-link aria-label="post link to 自动驾驶大数据领域深度调研报告" href=https://robert-xblog.vercel.app/tech/autonomous-driving-big-data/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>智能体设计模式资料汇总</h2></header><div class=entry-content><p>这是 Google 及相关高质量智能体设计模式的资料整理，涵盖从理论基础到实践应用的完整内容。
📚 中文资料 1. Prompt Engineering Guide - 大语言模型智能体简介 ⭐推荐 网址: https://www.promptingguide.ai/zh/research/llm-agents 语言: 中文 内容: 系统性介绍 LLM Agent 的核心组件 智能体（Agent）角色与设计 规划模块（Planning）：无反馈规划 vs 有反馈规划 记忆模块（Memory）：短期记忆与长期记忆 工具使用（Tools）：API、代码解释器等 ReAct、Reflexion 等设计模式 📚 英文资料（高质量参考） 2. A Survey on LLM-based Autonomous Agents ⭐经典论文 网址: https://arxiv.org/abs/2308.11432 PDF: https://arxiv.org/pdf/2308.11432 作者: 中国人民大学高瓴人工智能学院 内容: LLM Agent 的统一框架 社交科学、自然科学、工程领域的应用 评估策略与未来方向 3. DeepLearning.AI - Multi AI Agent Systems with crewAI 网址: https://www.deeplearning.ai/short-courses/multi-ai-agent-systems-with-crewai/ 时长: 2小时41分钟，18个视频课程 内容: 角色扮演（Role-playing） 记忆系统（短期/长期/共享记忆） 工具分配（Tools） 任务协作（串行、并行、层级） Guardrails 错误处理 4. LangChain 官方文档 - Agentic Concepts 网址: https://js.langchain.com/docs/concepts/agentic/ 内容: LangChain 的 Agent 架构 LangGraph 编排框架 Deep Agents 现代功能（自动压缩、虚拟文件系统、子代理） 🔗 Google 官方资源 资源 链接 Vertex AI Agent Builder https://cloud.google.com/generative-ai-app-builder/docs/agent-intro Gemini API Agents 文档 https://ai.google.dev/gemini-api/docs/agents Google Research https://research.google/pubs/ Kaggle Agents 白皮书 https://www.kaggle.com/whitepaper-agents 📋 核心设计模式总结 模式 说明 ReAct 推理+行动交替进行（Thought → Action → Observation） Chain-of-Thought 思维链，逐步推理 Tree of Thoughts 多路径思维树 Reflexion 自我反思与改进 Multi-Agent 多智能体协作（角色分工） RAG 检索增强生成 Tool Use 工具调用（搜索、代码解释器等） 📝 延伸阅读 MRKL: 结合 LLM 和专家模块 https://arxiv.org/abs/2205.00445 Toolformer: 微调 LLM 使用外部工具 API https://arxiv.org/abs/2302.04761 HuggingGPT: 利用 LLM 作为任务规划器 https://arxiv.org/abs/2303.17580 ChemCrow: 化学领域专用 Agent https://arxiv.org/abs/2304.05376 持续学习中，欢迎交流讨论。
...</p></div><footer class=entry-footer><span title='2026-02-22 15:00:00 +0800 CST'>February 22, 2026</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;159 words&nbsp;·&nbsp;Robert</footer><a class=entry-link aria-label="post link to 智能体设计模式资料汇总" href=https://robert-xblog.vercel.app/tech/agent-design-patterns/></a></article></main><footer class=footer><span>&copy; 2026 <a href=https://robert-xblog.vercel.app/>Robert | 程序员 · 生活家</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>